now using cuda
VOCAB_SIZE: 3482
data_size 1287
Epoch: 001/099 | Current Learning Rate: 0.001000
Epoch: 001/099 | Batch 0000/0011 | Loss: 8.315066
Epoch: 001/099 | Batch 0005/0011 | Loss: 6.861682
Epoch: 001/099 | Batch 0010/0011 | Loss: 6.424147
Time elapsed: 0.05 min
Epoch: 002/099 | Current Learning Rate: 0.001000
Epoch: 002/099 | Batch 0000/0011 | Loss: 6.162871
Epoch: 002/099 | Batch 0005/0011 | Loss: 5.975317
Epoch: 002/099 | Batch 0010/0011 | Loss: 5.949717
Time elapsed: 0.09 min
Epoch: 003/099 | Current Learning Rate: 0.001000
Epoch: 003/099 | Batch 0000/0011 | Loss: 5.863642
Epoch: 003/099 | Batch 0005/0011 | Loss: 5.825285
Epoch: 003/099 | Batch 0010/0011 | Loss: 5.887747
Time elapsed: 0.14 min
Epoch: 004/099 | Current Learning Rate: 0.001000
Epoch: 004/099 | Batch 0000/0011 | Loss: 5.729217
Epoch: 004/099 | Batch 0005/0011 | Loss: 5.755128
Epoch: 004/099 | Batch 0010/0011 | Loss: 5.412067
Time elapsed: 0.18 min
Epoch: 005/099 | Current Learning Rate: 0.001000
Epoch: 005/099 | Batch 0000/0011 | Loss: 5.743447
Epoch: 005/099 | Batch 0005/0011 | Loss: 5.660030
Epoch: 005/099 | Batch 0010/0011 | Loss: 5.683624
Time elapsed: 0.23 min
Epoch: 006/099 | Current Learning Rate: 0.001000
Epoch: 006/099 | Batch 0000/0011 | Loss: 5.518481
Epoch: 006/099 | Batch 0005/0011 | Loss: 5.509992
Epoch: 006/099 | Batch 0010/0011 | Loss: 5.595815
Time elapsed: 0.27 min
Epoch: 007/099 | Current Learning Rate: 0.001000
Epoch: 007/099 | Batch 0000/0011 | Loss: 5.387150
Epoch: 007/099 | Batch 0005/0011 | Loss: 5.405347
Epoch: 007/099 | Batch 0010/0011 | Loss: 5.288306
Time elapsed: 0.32 min
Epoch: 008/099 | Current Learning Rate: 0.001000
Epoch: 008/099 | Batch 0000/0011 | Loss: 5.288987
Epoch: 008/099 | Batch 0005/0011 | Loss: 5.217256
Epoch: 008/099 | Batch 0010/0011 | Loss: 5.010735
Time elapsed: 0.36 min
Epoch: 009/099 | Current Learning Rate: 0.001000
Epoch: 009/099 | Batch 0000/0011 | Loss: 5.142423
Epoch: 009/099 | Batch 0005/0011 | Loss: 5.123271
Epoch: 009/099 | Batch 0010/0011 | Loss: 5.093534
Time elapsed: 0.41 min
Epoch: 010/099 | Current Learning Rate: 0.001000
Epoch: 010/099 | Batch 0000/0011 | Loss: 4.984656
Epoch: 010/099 | Batch 0005/0011 | Loss: 5.007096
Epoch: 010/099 | Batch 0010/0011 | Loss: 4.828559
Time elapsed: 0.46 min
Epoch: 011/099 | Current Learning Rate: 0.001000
Epoch: 011/099 | Batch 0000/0011 | Loss: 4.847590
Epoch: 011/099 | Batch 0005/0011 | Loss: 4.872567
Epoch: 011/099 | Batch 0010/0011 | Loss: 4.672576
Time elapsed: 0.50 min
Epoch: 012/099 | Current Learning Rate: 0.001000
Epoch: 012/099 | Batch 0000/0011 | Loss: 4.748351
Epoch: 012/099 | Batch 0005/0011 | Loss: 4.743794
Epoch: 012/099 | Batch 0010/0011 | Loss: 4.548103
Time elapsed: 0.55 min
Epoch: 013/099 | Current Learning Rate: 0.001000
Epoch: 013/099 | Batch 0000/0011 | Loss: 4.693396
Epoch: 013/099 | Batch 0005/0011 | Loss: 4.584402
Epoch: 013/099 | Batch 0010/0011 | Loss: 4.126381
Time elapsed: 0.59 min
Epoch: 014/099 | Current Learning Rate: 0.001000
Epoch: 014/099 | Batch 0000/0011 | Loss: 4.422050
Epoch: 014/099 | Batch 0005/0011 | Loss: 4.444434
Epoch: 014/099 | Batch 0010/0011 | Loss: 4.524007
Time elapsed: 0.64 min
Epoch: 015/099 | Current Learning Rate: 0.001000
Epoch: 015/099 | Batch 0000/0011 | Loss: 4.373970
Epoch: 015/099 | Batch 0005/0011 | Loss: 4.302042
Epoch: 015/099 | Batch 0010/0011 | Loss: 4.324502
Time elapsed: 0.68 min
Epoch: 016/099 | Current Learning Rate: 0.001000
Epoch: 016/099 | Batch 0000/0011 | Loss: 4.304759
Epoch: 016/099 | Batch 0005/0011 | Loss: 4.341702
Epoch: 016/099 | Batch 0010/0011 | Loss: 4.473615
Time elapsed: 0.73 min
Epoch: 017/099 | Current Learning Rate: 0.001000
Epoch: 017/099 | Batch 0000/0011 | Loss: 4.141418
Epoch: 017/099 | Batch 0005/0011 | Loss: 4.130095
Epoch: 017/099 | Batch 0010/0011 | Loss: 4.047368
Time elapsed: 0.77 min
Epoch: 018/099 | Current Learning Rate: 0.001000
Epoch: 018/099 | Batch 0000/0011 | Loss: 4.086521
Epoch: 018/099 | Batch 0005/0011 | Loss: 4.096165
Epoch: 018/099 | Batch 0010/0011 | Loss: 3.713677
Time elapsed: 0.82 min
Epoch: 019/099 | Current Learning Rate: 0.001000
Epoch: 019/099 | Batch 0000/0011 | Loss: 3.951508
Epoch: 019/099 | Batch 0005/0011 | Loss: 3.900823
Epoch: 019/099 | Batch 0010/0011 | Loss: 4.154666
Time elapsed: 0.87 min
Epoch: 020/099 | Current Learning Rate: 0.001000
Epoch: 020/099 | Batch 0000/0011 | Loss: 3.858929
Epoch: 020/099 | Batch 0005/0011 | Loss: 3.813119
Epoch: 020/099 | Batch 0010/0011 | Loss: 3.764601
Time elapsed: 0.91 min
Epoch: 021/099 | Current Learning Rate: 0.001000
Epoch: 021/099 | Batch 0000/0011 | Loss: 3.578933
Epoch: 021/099 | Batch 0005/0011 | Loss: 3.592703
Epoch: 021/099 | Batch 0010/0011 | Loss: 3.627188
Time elapsed: 0.96 min
Epoch: 022/099 | Current Learning Rate: 0.001000
Epoch: 022/099 | Batch 0000/0011 | Loss: 3.681161
Epoch: 022/099 | Batch 0005/0011 | Loss: 3.565523
Epoch: 022/099 | Batch 0010/0011 | Loss: 3.581331
Time elapsed: 1.00 min
Epoch: 023/099 | Current Learning Rate: 0.001000
Epoch: 023/099 | Batch 0000/0011 | Loss: 3.457459
Epoch: 023/099 | Batch 0005/0011 | Loss: 3.396928
Epoch: 023/099 | Batch 0010/0011 | Loss: 3.159819
Time elapsed: 1.05 min
Epoch: 024/099 | Current Learning Rate: 0.001000
Epoch: 024/099 | Batch 0000/0011 | Loss: 3.379405
Epoch: 024/099 | Batch 0005/0011 | Loss: 3.359334
Epoch: 024/099 | Batch 0010/0011 | Loss: 3.355687
Time elapsed: 1.10 min
Epoch: 025/099 | Current Learning Rate: 0.001000
Epoch: 025/099 | Batch 0000/0011 | Loss: 3.341939
Epoch: 025/099 | Batch 0005/0011 | Loss: 3.298355
Epoch: 025/099 | Batch 0010/0011 | Loss: 2.934044
Time elapsed: 1.14 min
Epoch: 026/099 | Current Learning Rate: 0.001000
Epoch: 026/099 | Batch 0000/0011 | Loss: 3.189257
Epoch: 026/099 | Batch 0005/0011 | Loss: 3.154655
Epoch: 026/099 | Batch 0010/0011 | Loss: 2.723723
Time elapsed: 1.19 min
Epoch: 027/099 | Current Learning Rate: 0.001000
Epoch: 027/099 | Batch 0000/0011 | Loss: 3.035961
Epoch: 027/099 | Batch 0005/0011 | Loss: 3.001856
Epoch: 027/099 | Batch 0010/0011 | Loss: 2.741178
Time elapsed: 1.23 min
Epoch: 028/099 | Current Learning Rate: 0.001000
Epoch: 028/099 | Batch 0000/0011 | Loss: 2.937256
Epoch: 028/099 | Batch 0005/0011 | Loss: 2.929964
Epoch: 028/099 | Batch 0010/0011 | Loss: 2.656917
Time elapsed: 1.28 min
Epoch: 029/099 | Current Learning Rate: 0.001000
Epoch: 029/099 | Batch 0000/0011 | Loss: 2.850150
Epoch: 029/099 | Batch 0005/0011 | Loss: 2.897058
Epoch: 029/099 | Batch 0010/0011 | Loss: 2.778419
Time elapsed: 1.33 min
Epoch: 030/099 | Current Learning Rate: 0.001000
Epoch: 030/099 | Batch 0000/0011 | Loss: 2.702089
Epoch: 030/099 | Batch 0005/0011 | Loss: 2.696887
Epoch: 030/099 | Batch 0010/0011 | Loss: 2.734927
Time elapsed: 1.37 min
Epoch: 031/099 | Current Learning Rate: 0.001000
Epoch: 031/099 | Batch 0000/0011 | Loss: 2.613687
Epoch: 031/099 | Batch 0005/0011 | Loss: 2.743742
Epoch: 031/099 | Batch 0010/0011 | Loss: 2.539053
Time elapsed: 1.42 min
Epoch: 032/099 | Current Learning Rate: 0.001000
Epoch: 032/099 | Batch 0000/0011 | Loss: 2.561403
Epoch: 032/099 | Batch 0005/0011 | Loss: 2.619313
Epoch: 032/099 | Batch 0010/0011 | Loss: 2.687752
Time elapsed: 1.46 min
Epoch: 033/099 | Current Learning Rate: 0.001000
Epoch: 033/099 | Batch 0000/0011 | Loss: 2.499195
Epoch: 033/099 | Batch 0005/0011 | Loss: 2.513976
Epoch: 033/099 | Batch 0010/0011 | Loss: 2.533385
Time elapsed: 1.51 min
Epoch: 034/099 | Current Learning Rate: 0.001000
Epoch: 034/099 | Batch 0000/0011 | Loss: 2.289850
Epoch: 034/099 | Batch 0005/0011 | Loss: 2.453924
Epoch: 034/099 | Batch 0010/0011 | Loss: 2.477926
Time elapsed: 1.56 min
Epoch: 035/099 | Current Learning Rate: 0.001000
Epoch: 035/099 | Batch 0000/0011 | Loss: 2.341629
Epoch: 035/099 | Batch 0005/0011 | Loss: 2.327655
Epoch: 035/099 | Batch 0010/0011 | Loss: 1.970197
Time elapsed: 1.60 min
Epoch: 036/099 | Current Learning Rate: 0.001000
Epoch: 036/099 | Batch 0000/0011 | Loss: 2.143924
Epoch: 036/099 | Batch 0005/0011 | Loss: 2.218183
Epoch: 036/099 | Batch 0010/0011 | Loss: 2.193669
Time elapsed: 1.65 min
Epoch: 037/099 | Current Learning Rate: 0.001000
Epoch: 037/099 | Batch 0000/0011 | Loss: 2.203329
Epoch: 037/099 | Batch 0005/0011 | Loss: 2.263198
Epoch: 037/099 | Batch 0010/0011 | Loss: 2.392524
Time elapsed: 1.69 min
Epoch: 038/099 | Current Learning Rate: 0.001000
Epoch: 038/099 | Batch 0000/0011 | Loss: 2.158855
Epoch: 038/099 | Batch 0005/0011 | Loss: 2.218939
Epoch: 038/099 | Batch 0010/0011 | Loss: 2.474475
Time elapsed: 1.74 min
Epoch: 039/099 | Current Learning Rate: 0.001000
Epoch: 039/099 | Batch 0000/0011 | Loss: 2.031381
Epoch: 039/099 | Batch 0005/0011 | Loss: 2.162000
Epoch: 039/099 | Batch 0010/0011 | Loss: 2.006291
Time elapsed: 1.79 min
Epoch: 040/099 | Current Learning Rate: 0.001000
Epoch: 040/099 | Batch 0000/0011 | Loss: 1.954345
Epoch: 040/099 | Batch 0005/0011 | Loss: 1.982781
Epoch: 040/099 | Batch 0010/0011 | Loss: 1.810696
Time elapsed: 1.83 min
Epoch: 041/099 | Current Learning Rate: 0.001000
Epoch: 041/099 | Batch 0000/0011 | Loss: 1.746786
Epoch: 041/099 | Batch 0005/0011 | Loss: 1.802182
Epoch: 041/099 | Batch 0010/0011 | Loss: 1.805470
Time elapsed: 1.88 min
Epoch: 042/099 | Current Learning Rate: 0.001000
Epoch: 042/099 | Batch 0000/0011 | Loss: 1.686952
Epoch: 042/099 | Batch 0005/0011 | Loss: 1.769878
Epoch: 042/099 | Batch 0010/0011 | Loss: 1.685352
Time elapsed: 1.92 min
Epoch: 043/099 | Current Learning Rate: 0.001000
Epoch: 043/099 | Batch 0000/0011 | Loss: 1.571475
Epoch: 043/099 | Batch 0005/0011 | Loss: 1.789191
Epoch: 043/099 | Batch 0010/0011 | Loss: 1.915711
Time elapsed: 1.97 min
Epoch: 044/099 | Current Learning Rate: 0.001000
Epoch: 044/099 | Batch 0000/0011 | Loss: 1.638695
Epoch: 044/099 | Batch 0005/0011 | Loss: 1.779743
Epoch: 044/099 | Batch 0010/0011 | Loss: 1.546035
Time elapsed: 2.02 min
Epoch: 045/099 | Current Learning Rate: 0.001000
Epoch: 045/099 | Batch 0000/0011 | Loss: 1.543510
Epoch: 045/099 | Batch 0005/0011 | Loss: 1.644453
Epoch: 045/099 | Batch 0010/0011 | Loss: 1.663113
Time elapsed: 2.06 min
Epoch: 046/099 | Current Learning Rate: 0.001000
Epoch: 046/099 | Batch 0000/0011 | Loss: 1.492025
Epoch: 046/099 | Batch 0005/0011 | Loss: 1.494865
Epoch: 046/099 | Batch 0010/0011 | Loss: 1.446456
Time elapsed: 2.11 min
Epoch: 047/099 | Current Learning Rate: 0.001000
Epoch: 047/099 | Batch 0000/0011 | Loss: 1.401402
Epoch: 047/099 | Batch 0005/0011 | Loss: 1.411805
Epoch: 047/099 | Batch 0010/0011 | Loss: 1.396547
Time elapsed: 2.16 min
Epoch: 048/099 | Current Learning Rate: 0.001000
Epoch: 048/099 | Batch 0000/0011 | Loss: 1.283360
Epoch: 048/099 | Batch 0005/0011 | Loss: 1.386718
Epoch: 048/099 | Batch 0010/0011 | Loss: 1.338573
Time elapsed: 2.20 min
Epoch: 049/099 | Current Learning Rate: 0.001000
Epoch: 049/099 | Batch 0000/0011 | Loss: 1.261763
Epoch: 049/099 | Batch 0005/0011 | Loss: 1.219333
Epoch: 049/099 | Batch 0010/0011 | Loss: 1.153626
Time elapsed: 2.25 min
Epoch: 050/099 | Current Learning Rate: 0.001000
Epoch: 050/099 | Batch 0000/0011 | Loss: 1.143486
Epoch: 050/099 | Batch 0005/0011 | Loss: 1.122074
Epoch: 050/099 | Batch 0010/0011 | Loss: 1.206443
Time elapsed: 2.29 min
Epoch: 051/099 | Current Learning Rate: 0.001000
Epoch: 051/099 | Batch 0000/0011 | Loss: 1.040114
Epoch: 051/099 | Batch 0005/0011 | Loss: 1.139377
Epoch: 051/099 | Batch 0010/0011 | Loss: 1.073245
Time elapsed: 2.34 min
Epoch: 052/099 | Current Learning Rate: 0.001000
Epoch: 052/099 | Batch 0000/0011 | Loss: 0.988967
Epoch: 052/099 | Batch 0005/0011 | Loss: 1.084257
Epoch: 052/099 | Batch 0010/0011 | Loss: 1.154523
Time elapsed: 2.39 min
Epoch: 053/099 | Current Learning Rate: 0.001000
Epoch: 053/099 | Batch 0000/0011 | Loss: 1.000469
Epoch: 053/099 | Batch 0005/0011 | Loss: 1.109450
Epoch: 053/099 | Batch 0010/0011 | Loss: 1.046644
Time elapsed: 2.43 min
Epoch: 054/099 | Current Learning Rate: 0.001000
Epoch: 054/099 | Batch 0000/0011 | Loss: 0.935046
Epoch: 054/099 | Batch 0005/0011 | Loss: 1.008941
Epoch: 054/099 | Batch 0010/0011 | Loss: 0.864358
Time elapsed: 2.48 min
Epoch: 055/099 | Current Learning Rate: 0.001000
Epoch: 055/099 | Batch 0000/0011 | Loss: 0.847700
Epoch: 055/099 | Batch 0005/0011 | Loss: 0.900537
Epoch: 055/099 | Batch 0010/0011 | Loss: 0.828366
Time elapsed: 2.53 min
Epoch: 056/099 | Current Learning Rate: 0.001000
Epoch: 056/099 | Batch 0000/0011 | Loss: 0.790934
Epoch: 056/099 | Batch 0005/0011 | Loss: 0.836607
Epoch: 056/099 | Batch 0010/0011 | Loss: 0.734158
Time elapsed: 2.57 min
Epoch: 057/099 | Current Learning Rate: 0.001000
Epoch: 057/099 | Batch 0000/0011 | Loss: 0.762955
Epoch: 057/099 | Batch 0005/0011 | Loss: 0.803375
Epoch: 057/099 | Batch 0010/0011 | Loss: 0.742395
Time elapsed: 2.62 min
Epoch: 058/099 | Current Learning Rate: 0.001000
Epoch: 058/099 | Batch 0000/0011 | Loss: 0.675179
Epoch: 058/099 | Batch 0005/0011 | Loss: 0.724313
Epoch: 058/099 | Batch 0010/0011 | Loss: 0.698376
Time elapsed: 2.67 min
Epoch: 059/099 | Current Learning Rate: 0.001000
Epoch: 059/099 | Batch 0000/0011 | Loss: 0.704323
Epoch: 059/099 | Batch 0005/0011 | Loss: 0.751878
Epoch: 059/099 | Batch 0010/0011 | Loss: 0.826466
Time elapsed: 2.71 min
Epoch: 060/099 | Current Learning Rate: 0.001000
Epoch: 060/099 | Batch 0000/0011 | Loss: 0.680348
Epoch: 060/099 | Batch 0005/0011 | Loss: 0.720764
Epoch: 060/099 | Batch 0010/0011 | Loss: 0.545828
Time elapsed: 2.76 min
Epoch: 061/099 | Current Learning Rate: 0.001000
Epoch: 061/099 | Batch 0000/0011 | Loss: 0.587235
Epoch: 061/099 | Batch 0005/0011 | Loss: 0.679945
Epoch: 061/099 | Batch 0010/0011 | Loss: 0.709812
Time elapsed: 2.80 min
Epoch: 062/099 | Current Learning Rate: 0.001000
Epoch: 062/099 | Batch 0000/0011 | Loss: 0.535265
Epoch: 062/099 | Batch 0005/0011 | Loss: 0.604769
Epoch: 062/099 | Batch 0010/0011 | Loss: 0.645251
Time elapsed: 2.85 min
Epoch: 063/099 | Current Learning Rate: 0.001000
Epoch: 063/099 | Batch 0000/0011 | Loss: 0.509219
Epoch: 063/099 | Batch 0005/0011 | Loss: 0.589603
Epoch: 063/099 | Batch 0010/0011 | Loss: 0.504365
Time elapsed: 2.90 min
Epoch: 064/099 | Current Learning Rate: 0.001000
Epoch: 064/099 | Batch 0000/0011 | Loss: 0.477906
Epoch: 064/099 | Batch 0005/0011 | Loss: 0.552534
Epoch: 064/099 | Batch 0010/0011 | Loss: 0.517729
Time elapsed: 2.94 min
Epoch: 065/099 | Current Learning Rate: 0.001000
Epoch: 065/099 | Batch 0000/0011 | Loss: 0.435767
Epoch: 065/099 | Batch 0005/0011 | Loss: 0.482538
Epoch: 065/099 | Batch 0010/0011 | Loss: 0.515181
Time elapsed: 2.99 min
Epoch: 066/099 | Current Learning Rate: 0.001000
Epoch: 066/099 | Batch 0000/0011 | Loss: 0.398737
Epoch: 066/099 | Batch 0005/0011 | Loss: 0.426603
Epoch: 066/099 | Batch 0010/0011 | Loss: 0.409012
Time elapsed: 3.04 min
Epoch: 067/099 | Current Learning Rate: 0.001000
Epoch: 067/099 | Batch 0000/0011 | Loss: 0.370117
Epoch: 067/099 | Batch 0005/0011 | Loss: 0.437999
Epoch: 067/099 | Batch 0010/0011 | Loss: 0.349719
Time elapsed: 3.08 min
Epoch: 068/099 | Current Learning Rate: 0.001000
Epoch: 068/099 | Batch 0000/0011 | Loss: 0.370022
Epoch: 068/099 | Batch 0005/0011 | Loss: 0.378569
Epoch: 068/099 | Batch 0010/0011 | Loss: 0.404183
Time elapsed: 3.13 min
Epoch: 069/099 | Current Learning Rate: 0.001000
Epoch: 069/099 | Batch 0000/0011 | Loss: 0.289247
Epoch: 069/099 | Batch 0005/0011 | Loss: 0.341942
Epoch: 069/099 | Batch 0010/0011 | Loss: 0.561279
Time elapsed: 3.18 min
Epoch: 070/099 | Current Learning Rate: 0.001000
Epoch: 070/099 | Batch 0000/0011 | Loss: 0.317851
Epoch: 070/099 | Batch 0005/0011 | Loss: 0.327125
Epoch: 070/099 | Batch 0010/0011 | Loss: 0.281376
Time elapsed: 3.22 min
Epoch: 071/099 | Current Learning Rate: 0.001000
Epoch: 071/099 | Batch 0000/0011 | Loss: 0.276152
Epoch: 071/099 | Batch 0005/0011 | Loss: 0.295552
Epoch: 071/099 | Batch 0010/0011 | Loss: 0.360260
Time elapsed: 3.27 min
Epoch: 072/099 | Current Learning Rate: 0.001000
Epoch: 072/099 | Batch 0000/0011 | Loss: 0.255851
Epoch: 072/099 | Batch 0005/0011 | Loss: 0.310285
Epoch: 072/099 | Batch 0010/0011 | Loss: 0.207867
Time elapsed: 3.31 min
Epoch: 073/099 | Current Learning Rate: 0.001000
Epoch: 073/099 | Batch 0000/0011 | Loss: 0.231776
Epoch: 073/099 | Batch 0005/0011 | Loss: 0.238752
Epoch: 073/099 | Batch 0010/0011 | Loss: 0.231873
Time elapsed: 3.36 min
Epoch: 074/099 | Current Learning Rate: 0.001000
Epoch: 074/099 | Batch 0000/0011 | Loss: 0.191238
Epoch: 074/099 | Batch 0005/0011 | Loss: 0.243318
Epoch: 074/099 | Batch 0010/0011 | Loss: 0.172154
Time elapsed: 3.41 min
Epoch: 075/099 | Current Learning Rate: 0.001000
Epoch: 075/099 | Batch 0000/0011 | Loss: 0.186671
Epoch: 075/099 | Batch 0005/0011 | Loss: 0.223999
Epoch: 075/099 | Batch 0010/0011 | Loss: 0.214603
Time elapsed: 3.45 min
Epoch: 076/099 | Current Learning Rate: 0.001000
Epoch: 076/099 | Batch 0000/0011 | Loss: 0.174655
Epoch: 076/099 | Batch 0005/0011 | Loss: 0.215757
Epoch: 076/099 | Batch 0010/0011 | Loss: 0.197194
Time elapsed: 3.50 min
Epoch: 077/099 | Current Learning Rate: 0.001000
Epoch: 077/099 | Batch 0000/0011 | Loss: 0.167069
Epoch: 077/099 | Batch 0005/0011 | Loss: 0.213673
Epoch: 077/099 | Batch 0010/0011 | Loss: 0.182940
Time elapsed: 3.55 min
Epoch: 078/099 | Current Learning Rate: 0.001000
Epoch: 078/099 | Batch 0000/0011 | Loss: 0.156916
Epoch: 078/099 | Batch 0005/0011 | Loss: 0.189114
Epoch: 078/099 | Batch 0010/0011 | Loss: 0.153510
Time elapsed: 3.59 min
Epoch: 079/099 | Current Learning Rate: 0.001000
Epoch: 079/099 | Batch 0000/0011 | Loss: 0.152229
Epoch: 079/099 | Batch 0005/0011 | Loss: 0.182866
Epoch: 079/099 | Batch 0010/0011 | Loss: 0.198678
Time elapsed: 3.64 min
Epoch: 080/099 | Current Learning Rate: 0.001000
Epoch: 080/099 | Batch 0000/0011 | Loss: 0.150777
Epoch: 080/099 | Batch 0005/0011 | Loss: 0.186534
Epoch: 080/099 | Batch 0010/0011 | Loss: 0.164982
Time elapsed: 3.69 min
Epoch: 081/099 | Current Learning Rate: 0.001000
Epoch: 081/099 | Batch 0000/0011 | Loss: 0.144761
Epoch: 081/099 | Batch 0005/0011 | Loss: 0.186614
Epoch: 081/099 | Batch 0010/0011 | Loss: 0.221904
Time elapsed: 3.73 min
Epoch: 082/099 | Current Learning Rate: 0.001000
Epoch: 082/099 | Batch 0000/0011 | Loss: 0.167535
Epoch: 082/099 | Batch 0005/0011 | Loss: 0.204596
Epoch: 082/099 | Batch 0010/0011 | Loss: 0.184872
Time elapsed: 3.78 min
Epoch: 083/099 | Current Learning Rate: 0.001000
Epoch: 083/099 | Batch 0000/0011 | Loss: 0.169312
Epoch: 083/099 | Batch 0005/0011 | Loss: 0.208123
Epoch: 083/099 | Batch 0010/0011 | Loss: 0.148777
Time elapsed: 3.83 min
Epoch: 084/099 | Current Learning Rate: 0.001000
Epoch: 084/099 | Batch 0000/0011 | Loss: 0.193865
Epoch: 084/099 | Batch 0005/0011 | Loss: 0.219857
Epoch: 084/099 | Batch 0010/0011 | Loss: 0.224061
Time elapsed: 3.87 min
Epoch: 085/099 | Current Learning Rate: 0.001000
Epoch: 085/099 | Batch 0000/0011 | Loss: 0.194983
Epoch: 085/099 | Batch 0005/0011 | Loss: 0.230512
Epoch: 085/099 | Batch 0010/0011 | Loss: 0.209454
Time elapsed: 3.92 min
Epoch: 086/099 | Current Learning Rate: 0.001000
Epoch: 086/099 | Batch 0000/0011 | Loss: 0.221523
Epoch: 086/099 | Batch 0005/0011 | Loss: 0.231166
Epoch: 086/099 | Batch 0010/0011 | Loss: 0.206751
Time elapsed: 3.97 min
Epoch: 087/099 | Current Learning Rate: 0.001000
Epoch: 087/099 | Batch 0000/0011 | Loss: 0.183437
Epoch: 087/099 | Batch 0005/0011 | Loss: 0.206331
Epoch: 087/099 | Batch 0010/0011 | Loss: 0.221604
Time elapsed: 4.01 min
Epoch: 088/099 | Current Learning Rate: 0.001000
Epoch: 088/099 | Batch 0000/0011 | Loss: 0.181824
Epoch: 088/099 | Batch 0005/0011 | Loss: 0.226824
Epoch: 088/099 | Batch 0010/0011 | Loss: 0.214393
Time elapsed: 4.06 min
Epoch: 089/099 | Current Learning Rate: 0.001000
Epoch: 089/099 | Batch 0000/0011 | Loss: 0.185872
Epoch: 089/099 | Batch 0005/0011 | Loss: 0.209906
Epoch: 089/099 | Batch 0010/0011 | Loss: 0.308541
Time elapsed: 4.11 min
Epoch: 090/099 | Current Learning Rate: 0.001000
Epoch: 090/099 | Batch 0000/0011 | Loss: 0.184391
Epoch: 090/099 | Batch 0005/0011 | Loss: 0.219339
Epoch: 090/099 | Batch 0010/0011 | Loss: 0.217600
Epoch 00090: reducing learning rate of group 0 to 5.0000e-04.
Time elapsed: 4.15 min
Epoch: 091/099 | Current Learning Rate: 0.000500
Epoch: 091/099 | Batch 0000/0011 | Loss: 0.175877
Epoch: 091/099 | Batch 0005/0011 | Loss: 0.173206
Epoch: 091/099 | Batch 0010/0011 | Loss: 0.207507
Time elapsed: 4.20 min
Epoch: 092/099 | Current Learning Rate: 0.000500
Epoch: 092/099 | Batch 0000/0011 | Loss: 0.132053
Epoch: 092/099 | Batch 0005/0011 | Loss: 0.143021
Epoch: 092/099 | Batch 0010/0011 | Loss: 0.136842
Time elapsed: 4.24 min
Epoch: 093/099 | Current Learning Rate: 0.000500
Epoch: 093/099 | Batch 0000/0011 | Loss: 0.119139
Epoch: 093/099 | Batch 0005/0011 | Loss: 0.138505
Epoch: 093/099 | Batch 0010/0011 | Loss: 0.095202
Time elapsed: 4.29 min
Epoch: 094/099 | Current Learning Rate: 0.000500
Epoch: 094/099 | Batch 0000/0011 | Loss: 0.105511
Epoch: 094/099 | Batch 0005/0011 | Loss: 0.108737
Epoch: 094/099 | Batch 0010/0011 | Loss: 0.106814
Time elapsed: 4.34 min
Epoch: 095/099 | Current Learning Rate: 0.000500
Epoch: 095/099 | Batch 0000/0011 | Loss: 0.114026
Epoch: 095/099 | Batch 0005/0011 | Loss: 0.126946
Epoch: 095/099 | Batch 0010/0011 | Loss: 0.080746
Time elapsed: 4.38 min
Epoch: 096/099 | Current Learning Rate: 0.000500
Epoch: 096/099 | Batch 0000/0011 | Loss: 0.108349
Epoch: 096/099 | Batch 0005/0011 | Loss: 0.119265
Epoch: 096/099 | Batch 0010/0011 | Loss: 0.090451
Time elapsed: 4.43 min
Epoch: 097/099 | Current Learning Rate: 0.000500
Epoch: 097/099 | Batch 0000/0011 | Loss: 0.107268
Epoch: 097/099 | Batch 0005/0011 | Loss: 0.129778
Epoch: 097/099 | Batch 0010/0011 | Loss: 0.111958
Time elapsed: 4.48 min
Epoch: 098/099 | Current Learning Rate: 0.000500
Epoch: 098/099 | Batch 0000/0011 | Loss: 0.115137
Epoch: 098/099 | Batch 0005/0011 | Loss: 0.119555
Epoch: 098/099 | Batch 0010/0011 | Loss: 0.122607
Time elapsed: 4.52 min
Epoch: 099/099 | Current Learning Rate: 0.000500
Epoch: 099/099 | Batch 0000/0011 | Loss: 0.115844
Epoch: 099/099 | Batch 0005/0011 | Loss: 0.122102
Epoch: 099/099 | Batch 0010/0011 | Loss: 0.107221
Time elapsed: 4.57 min
Total Training Time: 4.57 min
