{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import opencc\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now using cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "num_epochs = 10\n",
    "context_len = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"now using\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5865, 0.4071, 0.3756, 0.9656, 0.6540],\n",
      "         [0.5460, 0.8481, 0.8738, 0.1942, 0.3260],\n",
      "         [0.9396, 0.4874, 0.4888, 0.8993, 0.2385]]])\n",
      "tensor([[[2.0109, 1.3946, 1.9574],\n",
      "         [1.3946, 1.9251, 1.6060],\n",
      "         [1.9574, 1.6060, 2.2249]]])\n",
      "tensor([[[0.4020, 0.2170, 0.3810],\n",
      "         [0.2541, 0.4320, 0.3139],\n",
      "         [0.3322, 0.2337, 0.4341]]])\n",
      "tensor([[[0.7123, 0.5334, 0.5269, 0.7729, 0.4245],\n",
      "         [0.6799, 0.6228, 0.6264, 0.6116, 0.3819],\n",
      "         [0.7303, 0.5450, 0.5412, 0.7565, 0.3970]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,3,5)\n",
    "print(x)\n",
    "raw_weights = torch.bmm(x, x.transpose(1, 2))\n",
    "print(raw_weights)\n",
    "weights = F.softmax(raw_weights, dim=2)\n",
    "print(weights)\n",
    "y = torch.bmm(weights, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = opencc.OpenCC(\"t2s\")\n",
    "\n",
    "\n",
    "def sentenceParse(para):\n",
    "    para = re.sub(r\"（.*?）\", \"\", para)\n",
    "    para = re.sub(r\"{.*?}\", \"\", para)\n",
    "    para = re.sub(r\"《.*?》\", \"\", para)\n",
    "    para = re.sub(r\"[\\[\\]]\", \"\", para)\n",
    "    para = \"\".join([s for s in para if s not in \"0123456789-\"])\n",
    "    para = re.sub(r\"。。\", \"。\", para)\n",
    "    para = converter.convert(para)\n",
    "    if \"𫗋\" in para or len(para) > context_len:\n",
    "        return \"\"\n",
    "    return para\n",
    "\n",
    "\n",
    "def parseRawData(author=None, constrain=None):\n",
    "    def handleJson(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        rst = []\n",
    "        for poetry in data:\n",
    "            if author and poetry.get(\"author\") != author:\n",
    "                continue\n",
    "\n",
    "            paragraphs = poetry.get(\"paragraphs\")\n",
    "            if any(\n",
    "                len(tr) != constrain and len(tr) != 0\n",
    "                for s in paragraphs\n",
    "                for tr in re.split(\"[，！。]\", s)\n",
    "                if constrain is not None\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            pdata = \"\".join(paragraphs)\n",
    "            pdata = sentenceParse(pdata)\n",
    "            if pdata:\n",
    "                rst.append(pdata)\n",
    "        return rst\n",
    "\n",
    "    poems = []\n",
    "    src_path = Path(\"./data/全唐诗/\")\n",
    "    for file_path in src_path.glob(\"poet.tang*\"):\n",
    "        poems.extend(handleJson(file_path))\n",
    "    # for file_path in src_path.glob(\"poet.song*\"):\n",
    "    # data.extend(handleJson(file_path))\n",
    "    return poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = parseRawData() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE: 7237\n",
      "data_size 46969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'秦': tensor([0]),\n",
       " '川': tensor([1]),\n",
       " '雄': tensor([2]),\n",
       " '帝': tensor([3]),\n",
       " '宅': tensor([4]),\n",
       " '，': tensor([5]),\n",
       " '函': tensor([6]),\n",
       " '谷': tensor([7]),\n",
       " '壮': tensor([8]),\n",
       " '皇': tensor([9]),\n",
       " '居': tensor([10]),\n",
       " '。': tensor([11]),\n",
       " '绮': tensor([12]),\n",
       " '殿': tensor([13]),\n",
       " '千': tensor([14]),\n",
       " '寻': tensor([15]),\n",
       " '起': tensor([16]),\n",
       " '离': tensor([17]),\n",
       " '宫': tensor([18]),\n",
       " '百': tensor([19]),\n",
       " '雉': tensor([20]),\n",
       " '余': tensor([21]),\n",
       " '连': tensor([22]),\n",
       " '甍': tensor([23]),\n",
       " '遥': tensor([24]),\n",
       " '接': tensor([25]),\n",
       " '汉': tensor([26]),\n",
       " '飞': tensor([27]),\n",
       " '观': tensor([28]),\n",
       " '迥': tensor([29]),\n",
       " '凌': tensor([30]),\n",
       " '虚': tensor([31]),\n",
       " '云': tensor([32]),\n",
       " '日': tensor([33]),\n",
       " '隐': tensor([34]),\n",
       " '层': tensor([35]),\n",
       " '阙': tensor([36]),\n",
       " '风': tensor([37]),\n",
       " '烟': tensor([38]),\n",
       " '出': tensor([39]),\n",
       " '疎': tensor([40]),\n",
       " '岩': tensor([41]),\n",
       " '廊': tensor([42]),\n",
       " '罢': tensor([43]),\n",
       " '机': tensor([44]),\n",
       " '务': tensor([45]),\n",
       " '崇': tensor([46]),\n",
       " '文': tensor([47]),\n",
       " '聊': tensor([48]),\n",
       " '驻': tensor([49]),\n",
       " '辇': tensor([50]),\n",
       " '玉': tensor([51]),\n",
       " '匣': tensor([52]),\n",
       " '启': tensor([53]),\n",
       " '龙': tensor([54]),\n",
       " '图': tensor([55]),\n",
       " '金': tensor([56]),\n",
       " '绳': tensor([57]),\n",
       " '披': tensor([58]),\n",
       " '凤': tensor([59]),\n",
       " '篆': tensor([60]),\n",
       " '韦': tensor([61]),\n",
       " '编': tensor([62]),\n",
       " '断': tensor([63]),\n",
       " '仍': tensor([64]),\n",
       " '续': tensor([65]),\n",
       " '缥': tensor([66]),\n",
       " '帙': tensor([67]),\n",
       " '舒': tensor([68]),\n",
       " '还': tensor([69]),\n",
       " '卷': tensor([70]),\n",
       " '对': tensor([71]),\n",
       " '此': tensor([72]),\n",
       " '乃': tensor([73]),\n",
       " '淹': tensor([74]),\n",
       " '留': tensor([75]),\n",
       " '欹': tensor([76]),\n",
       " '案': tensor([77]),\n",
       " '坟': tensor([78]),\n",
       " '典': tensor([79]),\n",
       " '移': tensor([80]),\n",
       " '步': tensor([81]),\n",
       " '词': tensor([82]),\n",
       " '林': tensor([83]),\n",
       " '停': tensor([84]),\n",
       " '舆': tensor([85]),\n",
       " '欣': tensor([86]),\n",
       " '武': tensor([87]),\n",
       " '宴': tensor([88]),\n",
       " '雕': tensor([89]),\n",
       " '弓': tensor([90]),\n",
       " '写': tensor([91]),\n",
       " '明': tensor([92]),\n",
       " '月': tensor([93]),\n",
       " '骏': tensor([94]),\n",
       " '马': tensor([95]),\n",
       " '疑': tensor([96]),\n",
       " '流': tensor([97]),\n",
       " '电': tensor([98]),\n",
       " '惊': tensor([99]),\n",
       " '雁': tensor([100]),\n",
       " '落': tensor([101]),\n",
       " '弦': tensor([102]),\n",
       " '啼': tensor([103]),\n",
       " '猿': tensor([104]),\n",
       " '悲': tensor([105]),\n",
       " '急': tensor([106]),\n",
       " '箭': tensor([107]),\n",
       " '阅': tensor([108]),\n",
       " '赏': tensor([109]),\n",
       " '诚': tensor([110]),\n",
       " '多': tensor([111]),\n",
       " '美': tensor([112]),\n",
       " '于': tensor([113]),\n",
       " '兹': tensor([114]),\n",
       " '忘': tensor([115]),\n",
       " '倦': tensor([116]),\n",
       " '鸣': tensor([117]),\n",
       " '笳': tensor([118]),\n",
       " '临': tensor([119]),\n",
       " '乐': tensor([120]),\n",
       " '馆': tensor([121]),\n",
       " '眺': tensor([122]),\n",
       " '听': tensor([123]),\n",
       " '欢': tensor([124]),\n",
       " '芳': tensor([125]),\n",
       " '节': tensor([126]),\n",
       " '管': tensor([127]),\n",
       " '韵': tensor([128]),\n",
       " '朱': tensor([129]),\n",
       " '清': tensor([130]),\n",
       " '歌': tensor([131]),\n",
       " '凝': tensor([132]),\n",
       " '白': tensor([133]),\n",
       " '雪': tensor([134]),\n",
       " '彩': tensor([135]),\n",
       " '肃': tensor([136]),\n",
       " '来': tensor([137]),\n",
       " '仪': tensor([138]),\n",
       " '玄': tensor([139]),\n",
       " '鹤': tensor([140]),\n",
       " '纷': tensor([141]),\n",
       " '成': tensor([142]),\n",
       " '列': tensor([143]),\n",
       " '去': tensor([144]),\n",
       " '郑': tensor([145]),\n",
       " '卫': tensor([146]),\n",
       " '声': tensor([147]),\n",
       " '雅': tensor([148]),\n",
       " '音': tensor([149]),\n",
       " '方': tensor([150]),\n",
       " '可': tensor([151]),\n",
       " '悦': tensor([152]),\n",
       " '辰': tensor([153]),\n",
       " '追': tensor([154]),\n",
       " '逸': tensor([155]),\n",
       " '趣': tensor([156]),\n",
       " '禁': tensor([157]),\n",
       " '苑': tensor([158]),\n",
       " '信': tensor([159]),\n",
       " '奇': tensor([160]),\n",
       " '桥': tensor([161]),\n",
       " '形': tensor([162]),\n",
       " '通': tensor([163]),\n",
       " '上': tensor([164]),\n",
       " '峰': tensor([165]),\n",
       " '势': tensor([166]),\n",
       " '危': tensor([167]),\n",
       " '霞': tensor([168]),\n",
       " '交': tensor([169]),\n",
       " '映': tensor([170]),\n",
       " '花': tensor([171]),\n",
       " '鸟': tensor([172]),\n",
       " '自': tensor([173]),\n",
       " '参': tensor([174]),\n",
       " '差': tensor([175]),\n",
       " '何': tensor([176]),\n",
       " '如': tensor([177]),\n",
       " '肆': tensor([178]),\n",
       " '辙': tensor([179]),\n",
       " '迹': tensor([180]),\n",
       " '？': tensor([181]),\n",
       " '万': tensor([182]),\n",
       " '里': tensor([183]),\n",
       " '瑶': tensor([184]),\n",
       " '池': tensor([185]),\n",
       " '盖': tensor([186]),\n",
       " '园': tensor([187]),\n",
       " '兰': tensor([188]),\n",
       " '桡': tensor([189]),\n",
       " '游': tensor([190]),\n",
       " '翠': tensor([191]),\n",
       " '渚': tensor([192]),\n",
       " '萍': tensor([193]),\n",
       " '间': tensor([194]),\n",
       " '乱': tensor([195]),\n",
       " '荷': tensor([196]),\n",
       " '处': tensor([197]),\n",
       " '香': tensor([198]),\n",
       " '举': tensor([199]),\n",
       " '桂': tensor([200]),\n",
       " '楫': tensor([201]),\n",
       " '满': tensor([202]),\n",
       " '中': tensor([203]),\n",
       " '振': tensor([204]),\n",
       " '长': tensor([205]),\n",
       " '屿': tensor([206]),\n",
       " '岂': tensor([207]),\n",
       " '必': tensor([208]),\n",
       " '汾': tensor([209]),\n",
       " '河': tensor([210]),\n",
       " '曲': tensor([211]),\n",
       " '为': tensor([212]),\n",
       " '所': tensor([213]),\n",
       " '双': tensor([214]),\n",
       " '昏': tensor([215]),\n",
       " '回': tensor([216]),\n",
       " '九': tensor([217]),\n",
       " '重': tensor([218]),\n",
       " '暮': tensor([219]),\n",
       " '散': tensor([220]),\n",
       " '初': tensor([221]),\n",
       " '碧': tensor([222]),\n",
       " '皎': tensor([223]),\n",
       " '澄': tensor([224]),\n",
       " '轻': tensor([225]),\n",
       " '素': tensor([226]),\n",
       " '搴': tensor([227]),\n",
       " '幌': tensor([228]),\n",
       " '玩': tensor([229]),\n",
       " '琴': tensor([230]),\n",
       " '书': tensor([231]),\n",
       " '开': tensor([232]),\n",
       " '轩': tensor([233]),\n",
       " '引': tensor([234]),\n",
       " '雾': tensor([235]),\n",
       " '斜': tensor([236]),\n",
       " '耿': tensor([237]),\n",
       " '阁': tensor([238]),\n",
       " '摇': tensor([239]),\n",
       " '树': tensor([240]),\n",
       " '难': tensor([241]),\n",
       " '再': tensor([242]),\n",
       " '逢': tensor([243]),\n",
       " '良': tensor([244]),\n",
       " '惜': tensor([245]),\n",
       " '酒': tensor([246]),\n",
       " '泛': tensor([247]),\n",
       " '罍': tensor([248]),\n",
       " '殽': tensor([249]),\n",
       " '陈': tensor([250]),\n",
       " '席': tensor([251]),\n",
       " '钟': tensor([252]),\n",
       " '合': tensor([253]),\n",
       " '尧': tensor([254]),\n",
       " '禹': tensor([255]),\n",
       " '兽': tensor([256]),\n",
       " '谐': tensor([257]),\n",
       " '石': tensor([258]),\n",
       " '得': tensor([259]),\n",
       " '志': tensor([260]),\n",
       " '寸': tensor([261]),\n",
       " '阴': tensor([262]),\n",
       " '怀': tensor([263]),\n",
       " '尺': tensor([264]),\n",
       " '璧': tensor([265]),\n",
       " '建': tensor([266]),\n",
       " '章': tensor([267]),\n",
       " '夕': tensor([268]),\n",
       " '二': tensor([269]),\n",
       " '八': tensor([270]),\n",
       " '尽': tensor([271]),\n",
       " '妖': tensor([272]),\n",
       " '妍': tensor([273]),\n",
       " '罗': tensor([274]),\n",
       " '昭': tensor([275]),\n",
       " '阳': tensor([276]),\n",
       " '芬': tensor([277]),\n",
       " '玳': tensor([278]),\n",
       " '瑁': tensor([279]),\n",
       " '筵': tensor([280]),\n",
       " '珮': tensor([281]),\n",
       " '星': tensor([282]),\n",
       " '正': tensor([283]),\n",
       " '动': tensor([284]),\n",
       " '扇': tensor([285]),\n",
       " '掩': tensor([286]),\n",
       " '圆': tensor([287]),\n",
       " '无': tensor([288]),\n",
       " '劳': tensor([289]),\n",
       " '悬': tensor([290]),\n",
       " '圃': tensor([291]),\n",
       " '即': tensor([292]),\n",
       " '神': tensor([293]),\n",
       " '仙': tensor([294]),\n",
       " '新': tensor([295]),\n",
       " '丰': tensor([296]),\n",
       " '谯': tensor([297]),\n",
       " '邑': tensor([298]),\n",
       " '荒': tensor([299]),\n",
       " '一': tensor([300]),\n",
       " '径': tensor([301]),\n",
       " '苔': tensor([302]),\n",
       " '古': tensor([303]),\n",
       " '半': tensor([304]),\n",
       " '阶': tensor([305]),\n",
       " '前': tensor([306]),\n",
       " '消': tensor([307]),\n",
       " '旧': tensor([308]),\n",
       " '水': tensor([309]),\n",
       " '昔': tensor([310]),\n",
       " '发': tensor([311]),\n",
       " '今': tensor([312]),\n",
       " '朝': tensor([313]),\n",
       " '辞': tensor([314]),\n",
       " '地': tensor([315]),\n",
       " '四': tensor([316]),\n",
       " '海': tensor([317]),\n",
       " '遂': tensor([318]),\n",
       " '家': tensor([319]),\n",
       " '慨': tensor([320]),\n",
       " '然': tensor([321]),\n",
       " '抚': tensor([322]),\n",
       " '劒': tensor([323]),\n",
       " '济': tensor([324]),\n",
       " '世': tensor([325]),\n",
       " '邀': tensor([326]),\n",
       " '名': tensor([327]),\n",
       " '旗': tensor([328]),\n",
       " '羽': tensor([329]),\n",
       " '天': tensor([330]),\n",
       " '行': tensor([331]),\n",
       " '徧': tensor([332]),\n",
       " '野': tensor([333]),\n",
       " '屯': tensor([334]),\n",
       " '骑': tensor([335]),\n",
       " '原': tensor([336]),\n",
       " '五': tensor([337]),\n",
       " '营': tensor([338]),\n",
       " '登': tensor([339]),\n",
       " '山': tensor([340]),\n",
       " '麾': tensor([341]),\n",
       " '背': tensor([342]),\n",
       " '纵': tensor([343]),\n",
       " '兵': tensor([344]),\n",
       " '在': tensor([345]),\n",
       " '戎': tensor([346]),\n",
       " '戈': tensor([347]),\n",
       " '宇': tensor([348]),\n",
       " '宙': tensor([349]),\n",
       " '平': tensor([350]),\n",
       " '卢': tensor([351]),\n",
       " '转': tensor([352]),\n",
       " '征': tensor([353]),\n",
       " '斾': tensor([354]),\n",
       " '丽': tensor([355]),\n",
       " '萦': tensor([356]),\n",
       " '似': tensor([357]),\n",
       " '带': tensor([358]),\n",
       " '气': tensor([359]),\n",
       " '楼': tensor([360]),\n",
       " '松': tensor([361]),\n",
       " '丈': tensor([362]),\n",
       " '兔': tensor([363]),\n",
       " '辉': tensor([364]),\n",
       " '照': tensor([365]),\n",
       " '辽': tensor([366]),\n",
       " '碣': tensor([367]),\n",
       " '光': tensor([368]),\n",
       " '暂': tensor([369]),\n",
       " '隔': tensor([370]),\n",
       " '缀': tensor([371]),\n",
       " '魄': tensor([372]),\n",
       " '枝': tensor([373]),\n",
       " '轮': tensor([374]),\n",
       " '亏': tensor([375]),\n",
       " '镜': tensor([376]),\n",
       " '缺': tensor([377]),\n",
       " '城': tensor([378]),\n",
       " '却': tensor([379]),\n",
       " '影': tensor([380]),\n",
       " '晕': tensor([381]),\n",
       " '围': tensor([382]),\n",
       " '结': tensor([383]),\n",
       " '跸': tensor([384]),\n",
       " '俯': tensor([385]),\n",
       " '都': tensor([386]),\n",
       " '氛': tensor([387]),\n",
       " '灭': tensor([388]),\n",
       " '隰': tensor([389]),\n",
       " '岭': tensor([390]),\n",
       " '峻': tensor([391]),\n",
       " '高': tensor([392]),\n",
       " '下': tensor([393]),\n",
       " '浪': tensor([394]),\n",
       " '浅': tensor([395]),\n",
       " '深': tensor([396]),\n",
       " '斑': tensor([397]),\n",
       " '红': tensor([398]),\n",
       " '粧': tensor([399]),\n",
       " '橤': tensor([400]),\n",
       " '青': tensor([401]),\n",
       " '压': tensor([402]),\n",
       " '溜': tensor([403]),\n",
       " '荆': tensor([404]),\n",
       " '傅': tensor([405]),\n",
       " '想': tensor([406]),\n",
       " '窥': tensor([407]),\n",
       " '访': tensor([408]),\n",
       " '莘': tensor([409]),\n",
       " '情': tensor([410]),\n",
       " '巨': tensor([411]),\n",
       " '以': tensor([412]),\n",
       " '舟': tensor([413]),\n",
       " '伫': tensor([414]),\n",
       " '时': tensor([415]),\n",
       " '英': tensor([416]),\n",
       " '春': tensor([417]),\n",
       " '搜': tensor([418]),\n",
       " '驰': tensor([419]),\n",
       " '骨': tensor([420]),\n",
       " '总': tensor([421]),\n",
       " '辔': tensor([422]),\n",
       " '锦': tensor([423]),\n",
       " '瀁': tensor([424]),\n",
       " '翻': tensor([425]),\n",
       " '堤': tensor([426]),\n",
       " '倒': tensor([427]),\n",
       " '插': tensor([428]),\n",
       " '波': tensor([429]),\n",
       " '秋': tensor([430]),\n",
       " '棹': tensor([431]),\n",
       " '峦': tensor([432]),\n",
       " '渭': tensor([433]),\n",
       " '嶂': tensor([434]),\n",
       " '扶': tensor([435]),\n",
       " '入': tensor([436]),\n",
       " '贮': tensor([437]),\n",
       " '叠': tensor([438]),\n",
       " '若': tensor([439]),\n",
       " '夜': tensor([440]),\n",
       " '复': tensor([441]),\n",
       " '岫': tensor([442]),\n",
       " '全': tensor([443]),\n",
       " '恬': tensor([444]),\n",
       " '虑': tensor([445]),\n",
       " '寒': tensor([446]),\n",
       " '随': tensor([447]),\n",
       " '穷': tensor([448]),\n",
       " '律': tensor([449]),\n",
       " '变': tensor([450]),\n",
       " '逐': tensor([451]),\n",
       " '飘': tensor([452]),\n",
       " '柳': tensor([453]),\n",
       " '晚': tensor([454]),\n",
       " '梅': tensor([455]),\n",
       " '竹': tensor([456]),\n",
       " '绿': tensor([457]),\n",
       " '沼': tensor([458]),\n",
       " '芝': tensor([459]),\n",
       " '田': tensor([460]),\n",
       " '巧': tensor([461]),\n",
       " '鸎': tensor([462]),\n",
       " '怡': tensor([463]),\n",
       " '晴': tensor([464]),\n",
       " '弥': tensor([465]),\n",
       " '喜': tensor([466]),\n",
       " '晃': tensor([467]),\n",
       " '色': tensor([468]),\n",
       " '鱼': tensor([469]),\n",
       " '跃': tensor([470]),\n",
       " '不': tensor([471]),\n",
       " '同': tensor([472]),\n",
       " '异': tensor([473]),\n",
       " '寄': tensor([474]),\n",
       " '言': tensor([475]),\n",
       " '博': tensor([476]),\n",
       " '者': tensor([477]),\n",
       " '知': tensor([478]),\n",
       " '予': tensor([479]),\n",
       " '物': tensor([480]),\n",
       " '外': tensor([481]),\n",
       " '夏': tensor([482]),\n",
       " '昨': tensor([483]),\n",
       " '灰': tensor([484]),\n",
       " '晷': tensor([485]),\n",
       " '峨': tensor([486]),\n",
       " '嵋': tensor([487]),\n",
       " '洞': tensor([488]),\n",
       " '庭': tensor([489]),\n",
       " '渐': tensor([490]),\n",
       " '幽': tensor([491]),\n",
       " '菊': tensor([492]),\n",
       " '黄': tensor([493]),\n",
       " '灞': tensor([494]),\n",
       " '涘': tensor([495]),\n",
       " '运': tensor([496]),\n",
       " '叹': tensor([497]),\n",
       " '含': tensor([498]),\n",
       " '毫': tensor([499]),\n",
       " '属': tensor([500]),\n",
       " '微': tensor([501]),\n",
       " '理': tensor([502]),\n",
       " '蓟': tensor([503]),\n",
       " '门': tensor([504]),\n",
       " '叶': tensor([505]),\n",
       " '小': tensor([506]),\n",
       " '避': tensor([507]),\n",
       " '提': tensor([508]),\n",
       " '壶': tensor([509]),\n",
       " '岸': tensor([510]),\n",
       " '兴': tensor([511]),\n",
       " '芙': tensor([512]),\n",
       " '蓉': tensor([513]),\n",
       " '欲': tensor([514]),\n",
       " '凉': tensor([515]),\n",
       " '早': tensor([516]),\n",
       " '巢': tensor([517]),\n",
       " '空': tensor([518]),\n",
       " '燕': tensor([519]),\n",
       " '亭': tensor([520]),\n",
       " '牖': tensor([521]),\n",
       " '度': tensor([522]),\n",
       " '尚': tensor([523]),\n",
       " '染': tensor([524]),\n",
       " '残': tensor([525]),\n",
       " '犹': tensor([526]),\n",
       " '承': tensor([527]),\n",
       " '露': tensor([528]),\n",
       " '衣': tensor([529]),\n",
       " '封': tensor([530]),\n",
       " '历': tensor([531]),\n",
       " '览': tensor([532]),\n",
       " '极': tensor([533]),\n",
       " '咫': tensor([534]),\n",
       " '输': tensor([535]),\n",
       " '浮': tensor([536]),\n",
       " '烧': tensor([537]),\n",
       " '霜': tensor([538]),\n",
       " '华': tensor([539]),\n",
       " '净': tensor([540]),\n",
       " '冰': tensor([541]),\n",
       " '迳': tensor([542]),\n",
       " '丛': tensor([543]),\n",
       " '约': tensor([544]),\n",
       " '分': tensor([545]),\n",
       " '抽': tensor([546]),\n",
       " '思': tensor([547]),\n",
       " '滋': tensor([548]),\n",
       " '泉': tensor([549]),\n",
       " '侧': tensor([550]),\n",
       " '衔': tensor([551]),\n",
       " '宵': tensor([552]),\n",
       " '珠': tensor([553]),\n",
       " '穿': tensor([554]),\n",
       " '晓': tensor([555]),\n",
       " '蝉': tensor([556]),\n",
       " '觉': tensor([557]),\n",
       " '冷': tensor([558]),\n",
       " '萤': tensor([559]),\n",
       " '火': tensor([560]),\n",
       " '温': tensor([561]),\n",
       " '生': tensor([562]),\n",
       " '戏': tensor([563]),\n",
       " '晨': tensor([564]),\n",
       " '浦': tensor([565]),\n",
       " '集': tensor([566]),\n",
       " '栖': tensor([567]),\n",
       " '鸿': tensor([568]),\n",
       " '飒': tensor([569]),\n",
       " '吹': tensor([570]),\n",
       " '炽': tensor([571]),\n",
       " '萧': tensor([572]),\n",
       " '条': tensor([573]),\n",
       " '关': tensor([574]),\n",
       " '塞': tensor([575]),\n",
       " '飏': tensor([576]),\n",
       " '蓬': tensor([577]),\n",
       " '瀛': tensor([578]),\n",
       " '拂': tensor([579]),\n",
       " '响': tensor([580]),\n",
       " '织': tensor([581]),\n",
       " '大': tensor([582]),\n",
       " '威': tensor([583]),\n",
       " '加': tensor([584]),\n",
       " '罩': tensor([585]),\n",
       " '远': tensor([586]),\n",
       " '喷': tensor([587]),\n",
       " '雨': tensor([588]),\n",
       " '低': tensor([589]),\n",
       " '腹': tensor([590]),\n",
       " '足': tensor([591]),\n",
       " '洒': tensor([592]),\n",
       " '阿': tensor([593]),\n",
       " '泫': tensor([594]),\n",
       " '缔': tensor([595]),\n",
       " '蒙': tensor([596]),\n",
       " '添': tensor([597]),\n",
       " '丝': tensor([598]),\n",
       " '密': tensor([599]),\n",
       " '洁': tensor([600]),\n",
       " '曜': tensor([601]),\n",
       " '装': tensor([602]),\n",
       " '墀': tensor([603]),\n",
       " '晖': tensor([604]),\n",
       " '玑': tensor([605]),\n",
       " '妆': tensor([606]),\n",
       " '台': tensor([607]),\n",
       " '粉': tensor([608]),\n",
       " '点': tensor([609]),\n",
       " '北': tensor([610]),\n",
       " '三': tensor([611]),\n",
       " '南': tensor([612]),\n",
       " '荣': tensor([613]),\n",
       " '莺': tensor([614]),\n",
       " '弄': tensor([615]),\n",
       " '瀑': tensor([616]),\n",
       " '应': tensor([617]),\n",
       " '向': tensor([618]),\n",
       " '心': tensor([619]),\n",
       " '杨': tensor([620]),\n",
       " '就': tensor([621]),\n",
       " '调': tensor([622]),\n",
       " '轸': tensor([623]),\n",
       " '坐': tensor([624]),\n",
       " '相': tensor([625]),\n",
       " '乌': tensor([626]),\n",
       " '岑': tensor([627]),\n",
       " '溪': tensor([628]),\n",
       " '藿': tensor([629]),\n",
       " '葵': tensor([630]),\n",
       " '倾': tensor([631]),\n",
       " '杂': tensor([632]),\n",
       " '檐': tensor([633]),\n",
       " '架': tensor([634]),\n",
       " '攒': tensor([635]),\n",
       " '镂': tensor([636]),\n",
       " '槛': tensor([637]),\n",
       " '栊': tensor([638]),\n",
       " '梨': tensor([639]),\n",
       " '始': tensor([640]),\n",
       " '莫': tensor([641]),\n",
       " '昆': tensor([642]),\n",
       " '暗': tensor([643]),\n",
       " '共': tensor([644]),\n",
       " '杯': tensor([645]),\n",
       " '伴': tensor([646]),\n",
       " '塘': tensor([647]),\n",
       " '携': tensor([648]),\n",
       " '手': tensor([649]),\n",
       " '航': tensor([650]),\n",
       " '船': tensor([651]),\n",
       " '细': tensor([652]),\n",
       " '定': tensor([653]),\n",
       " '凫': tensor([654]),\n",
       " '有': tensor([655]),\n",
       " '莲': tensor([656]),\n",
       " '稀': tensor([657]),\n",
       " '钏': tensor([658]),\n",
       " '广': tensor([659]),\n",
       " '櫂': tensor([660]),\n",
       " '归': tensor([661]),\n",
       " '景': tensor([662]),\n",
       " '洛': tensor([663]),\n",
       " '颜': tensor([664]),\n",
       " '津': tensor([665]),\n",
       " '乔': tensor([666]),\n",
       " '柯': tensor([667]),\n",
       " '啭': tensor([668]),\n",
       " '娇': tensor([669]),\n",
       " '人': tensor([670]),\n",
       " '作': tensor([671]),\n",
       " '实': tensor([672]),\n",
       " '珍': tensor([673]),\n",
       " '衡': tensor([674]),\n",
       " '蹊': tensor([675]),\n",
       " '蝶': tensor([676]),\n",
       " '脆': tensor([677]),\n",
       " '顾': tensor([678]),\n",
       " '灵': tensor([679]),\n",
       " '非': tensor([680]),\n",
       " '七': tensor([681]),\n",
       " '值': tensor([682]),\n",
       " '鹢': tensor([683]),\n",
       " '缆': tensor([684]),\n",
       " '近': tensor([685]),\n",
       " '腾': tensor([686]),\n",
       " '状': tensor([687]),\n",
       " '虹': tensor([688]),\n",
       " '屈': tensor([689]),\n",
       " '伸': tensor([690]),\n",
       " '乍': tensor([691]),\n",
       " '依': tensor([692]),\n",
       " '掣': tensor([693]),\n",
       " '曳': tensor([694]),\n",
       " '或': tensor([695]),\n",
       " '念': tensor([696]),\n",
       " '薄': tensor([697]),\n",
       " '质': tensor([698]),\n",
       " '翅': tensor([699]),\n",
       " '强': tensor([700]),\n",
       " '凿': tensor([701]),\n",
       " '奉': tensor([702]),\n",
       " '仗': tensor([703]),\n",
       " '战': tensor([704]),\n",
       " '鳞': tensor([705]),\n",
       " '骋': tensor([706]),\n",
       " '翼': tensor([707]),\n",
       " '未': tensor([708]),\n",
       " '展': tensor([709]),\n",
       " '六': tensor([710]),\n",
       " '术': tensor([711]),\n",
       " '先': tensor([712]),\n",
       " '篑': tensor([713]),\n",
       " '功': tensor([714]),\n",
       " '防': tensor([715]),\n",
       " '身': tensor([716]),\n",
       " '乏': tensor([717]),\n",
       " '智': tensor([718]),\n",
       " '殉': tensor([719]),\n",
       " '命': tensor([720]),\n",
       " '忠': tensor([721]),\n",
       " '晦': tensor([722]),\n",
       " '暄': tensor([723]),\n",
       " '呈': tensor([724]),\n",
       " '笑': tensor([725]),\n",
       " '襟': tensor([726]),\n",
       " '望': tensor([727]),\n",
       " '目': tensor([728]),\n",
       " '畅': tensor([729]),\n",
       " '帷': tensor([730]),\n",
       " '阵': tensor([731]),\n",
       " '钉': tensor([732]),\n",
       " '摅': tensor([733]),\n",
       " '俗': tensor([734]),\n",
       " '尘': tensor([735]),\n",
       " '帏': tensor([736]),\n",
       " '疾': tensor([737]),\n",
       " '噪': tensor([738]),\n",
       " '迟': tensor([739]),\n",
       " '吐': tensor([740]),\n",
       " '愁': tensor([741]),\n",
       " '独': tensor([742]),\n",
       " '将': tensor([743]),\n",
       " '数': tensor([744]),\n",
       " '几': tensor([745]),\n",
       " '碎': tensor([746]),\n",
       " '缬': tensor([747]),\n",
       " '直': tensor([748]),\n",
       " '见': tensor([749]),\n",
       " '眉': tensor([750]),\n",
       " '爽': tensor([751]),\n",
       " '片': tensor([752]),\n",
       " '且': tensor([753]),\n",
       " '娱': tensor([754]),\n",
       " '静': tensor([755]),\n",
       " '漏': tensor([756]),\n",
       " '公': tensor([757]),\n",
       " '侯': tensor([758]),\n",
       " '帘': tensor([759]),\n",
       " '烛': tensor([760]),\n",
       " '燄': tensor([761]),\n",
       " '绣': tensor([762]),\n",
       " '柱': tensor([763]),\n",
       " '与': tensor([764]),\n",
       " '遒': tensor([765]),\n",
       " '鲸': tensor([766]),\n",
       " '劫': tensor([767]),\n",
       " '烬': tensor([768]),\n",
       " '沙': tensor([769]),\n",
       " '冻': tensor([770]),\n",
       " '遽': tensor([771]),\n",
       " '西': tensor([772]),\n",
       " '迎': tensor([773]),\n",
       " '慙': tensor([774]),\n",
       " '破': tensor([775]),\n",
       " '谢': tensor([776]),\n",
       " '年': tensor([777]),\n",
       " '冬': tensor([778]),\n",
       " '暖': tensor([779]),\n",
       " '馥': tensor([780]),\n",
       " '盘': tensor([781]),\n",
       " '故': tensor([782]),\n",
       " '岁': tensor([783]),\n",
       " '送': tensor([784]),\n",
       " '纪': tensor([785]),\n",
       " '献': tensor([786]),\n",
       " '促': tensor([787]),\n",
       " '终': tensor([788]),\n",
       " '待': tensor([789]),\n",
       " '曙': tensor([790]),\n",
       " '和': tensor([791]),\n",
       " '涧': tensor([792]),\n",
       " '宿': tensor([793]),\n",
       " '湿': tensor([794]),\n",
       " '次': tensor([795]),\n",
       " '沾': tensor([796]),\n",
       " '更': tensor([797]),\n",
       " '鲜': tensor([798]),\n",
       " '聚': tensor([799]),\n",
       " '触': tensor([800]),\n",
       " '横': tensor([801]),\n",
       " '惑': tensor([802]),\n",
       " '楚': tensor([803]),\n",
       " '君': tensor([804]),\n",
       " '紫': tensor([805]),\n",
       " '栋': tensor([806]),\n",
       " '舞': tensor([807]),\n",
       " '箫': tensor([808]),\n",
       " '学': tensor([809]),\n",
       " '收': tensor([810]),\n",
       " '障': tensor([811]),\n",
       " '髣': tensor([812]),\n",
       " '髴': tensor([813]),\n",
       " '飖': tensor([814]),\n",
       " '因': tensor([815]),\n",
       " '冠': tensor([816]),\n",
       " '已': tensor([817]),\n",
       " '熏': tensor([818]),\n",
       " '浓': tensor([819]),\n",
       " '蔽': tensor([820]),\n",
       " '当': tensor([821]),\n",
       " '隋': tensor([822]),\n",
       " '淑': tensor([823]),\n",
       " '媚': tensor([824]),\n",
       " '场': tensor([825]),\n",
       " '传': tensor([826]),\n",
       " '会': tensor([827]),\n",
       " '须': tensor([828]),\n",
       " '子': tensor([829]),\n",
       " '折': tensor([830]),\n",
       " '佩': tensor([831]),\n",
       " '秀': tensor([832]),\n",
       " '垂': tensor([833]),\n",
       " '银': tensor([834]),\n",
       " '钩': tensor([835]),\n",
       " '户': tensor([836]),\n",
       " '惟': tensor([837]),\n",
       " '房': tensor([838]),\n",
       " '托': tensor([839]),\n",
       " '讵': tensor([840]),\n",
       " '肯': tensor([841]),\n",
       " '迷': tensor([842]),\n",
       " '只': tensor([843]),\n",
       " '纤': tensor([844]),\n",
       " '饮': tensor([845]),\n",
       " '泾': tensor([846]),\n",
       " '奔': tensor([847]),\n",
       " '络': tensor([848]),\n",
       " '缨': tensor([849]),\n",
       " '纹': tensor([850]),\n",
       " '荇': tensor([851]),\n",
       " '绕': tensor([852]),\n",
       " '蹄': tensor([853]),\n",
       " '鞍': tensor([854]),\n",
       " '种': tensor([855]),\n",
       " '晞': tensor([856]),\n",
       " '劲': tensor([857]),\n",
       " '凋': tensor([858]),\n",
       " '持': tensor([859]),\n",
       " '后': tensor([860]),\n",
       " '掌': tensor([861]),\n",
       " '耀': tensor([862]),\n",
       " '闱': tensor([863]),\n",
       " '驭': tensor([864]),\n",
       " '隙': tensor([865]),\n",
       " '摧': tensor([866]),\n",
       " '藏': tensor([867]),\n",
       " '态': tensor([868]),\n",
       " '抑': tensor([869]),\n",
       " '袖': tensor([870]),\n",
       " '驶': tensor([871]),\n",
       " '弹': tensor([872]),\n",
       " '缓': tensor([873]),\n",
       " '陇': tensor([874]),\n",
       " '恨': tensor([875]),\n",
       " '代': tensor([876]),\n",
       " '暧': tensor([877]),\n",
       " '指': tensor([878]),\n",
       " '梁': tensor([879]),\n",
       " '孤': tensor([880]),\n",
       " '别': tensor([881]),\n",
       " '路': tensor([882]),\n",
       " '袂': tensor([883]),\n",
       " '巾': tensor([884]),\n",
       " '泪': tensor([885]),\n",
       " '用': tensor([886]),\n",
       " '觞': tensor([887]),\n",
       " '琯': tensor([888]),\n",
       " '镇': tensor([889]),\n",
       " '是': tensor([890]),\n",
       " '蟠': tensor([891]),\n",
       " '堪': tensor([892]),\n",
       " '激': tensor([893]),\n",
       " '贞': tensor([894]),\n",
       " '砌': tensor([895]),\n",
       " '贯': tensor([896]),\n",
       " '翔': tensor([897]),\n",
       " '根': tensor([898]),\n",
       " '盈': tensor([899]),\n",
       " '干': tensor([900]),\n",
       " '倚': tensor([901]),\n",
       " '荫': tensor([902]),\n",
       " '磴': tensor([903]),\n",
       " '草': tensor([904]),\n",
       " '板': tensor([905]),\n",
       " '荡': tensor([906]),\n",
       " '识': tensor([907]),\n",
       " '臣': tensor([908]),\n",
       " '勇': tensor([909]),\n",
       " '夫': tensor([910]),\n",
       " '安': tensor([911]),\n",
       " '义': tensor([912]),\n",
       " '仁': tensor([913]),\n",
       " '太': tensor([914]),\n",
       " '液': tensor([915]),\n",
       " '才': tensor([916]),\n",
       " '车': tensor([917]),\n",
       " '鸡': tensor([918]),\n",
       " '崖': tensor([919]),\n",
       " '吟': tensor([920]),\n",
       " '醽': tensor([921]),\n",
       " '醁': tensor([922]),\n",
       " '胜': tensor([923]),\n",
       " '涛': tensor([924]),\n",
       " '过': tensor([925]),\n",
       " '䪥': tensor([926]),\n",
       " '醉': tensor([927]),\n",
       " '醒': tensor([928]),\n",
       " '十': tensor([929]),\n",
       " '味': tensor([930]),\n",
       " '败': tensor([931]),\n",
       " '绝': tensor([932]),\n",
       " '域': tensor([933]),\n",
       " '降': tensor([934]),\n",
       " '附': tensor([935]),\n",
       " '表': tensor([936]),\n",
       " '事': tensor([937]),\n",
       " '圣': tensor([938]),\n",
       " '敛': tensor([939]),\n",
       " '禅': tensor([940]),\n",
       " '常': tensor([941]),\n",
       " '具': tensor([942]),\n",
       " '礼': tensor([943]),\n",
       " '告': tensor([944]),\n",
       " '耻': tensor([945]),\n",
       " '酬': tensor([946]),\n",
       " '王': tensor([947]),\n",
       " '除': tensor([948]),\n",
       " '凶': tensor([949]),\n",
       " '报': tensor([950]),\n",
       " '乘': tensor([951]),\n",
       " '匹': tensor([952]),\n",
       " '驱': tensor([953]),\n",
       " '毛': tensor([954]),\n",
       " '虽': tensor([955]),\n",
       " '闻': tensor([956]),\n",
       " '驾': tensor([957]),\n",
       " '越': tensor([958]),\n",
       " '俱': tensor([959]),\n",
       " '阻': tensor([960]),\n",
       " '敍': tensor([961]),\n",
       " '璜': tensor([962]),\n",
       " '靥': tensor([963]),\n",
       " '谁': tensor([964]),\n",
       " '能': tensor([965]),\n",
       " '操': tensor([966]),\n",
       " '杼': tensor([967]),\n",
       " '濯': tensor([968]),\n",
       " '澜': tensor([969]),\n",
       " '霓': tensor([970]),\n",
       " '裳': tensor([971]),\n",
       " '俨': tensor([972]),\n",
       " '潢': tensor([973]),\n",
       " '梭': tensor([974]),\n",
       " '伤': tensor([975]),\n",
       " '郊': tensor([976]),\n",
       " '旌': tensor([977]),\n",
       " '湍': tensor([978]),\n",
       " '福': tensor([979]),\n",
       " '畿': tensor([980]),\n",
       " '法': tensor([981]),\n",
       " '丹': tensor([982]),\n",
       " '宝': tensor([983]),\n",
       " '幡': tensor([984]),\n",
       " '仞': tensor([985]),\n",
       " '耸': tensor([986]),\n",
       " '团': tensor([987]),\n",
       " '笼': tensor([988]),\n",
       " '帐': tensor([989]),\n",
       " '网': tensor([990]),\n",
       " '寥': tensor([991]),\n",
       " '廓': tensor([992]),\n",
       " '超': tensor([993]),\n",
       " '煖': tensor([994]),\n",
       " '绶': tensor([995]),\n",
       " '芽': tensor([996]),\n",
       " '嫩': tensor([997]),\n",
       " '□': tensor([998]),\n",
       " '两': tensor([999]),\n",
       " ...}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建词汇表\n",
    "word_to_index = {}\n",
    "for poem in poems:\n",
    "    for word in poem:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "word_to_index[\"<EOP>\"] = len(word_to_index)  # End Of Poem token\n",
    "word_to_index[\"<START>\"] = len(word_to_index)  # Start token\n",
    "index_to_word = {index: word for word, index in word_to_index.items()}\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "\n",
    "print(\"VOCAB_SIZE:\", vocab_size)\n",
    "print(\"data_size\", len(poems))\n",
    "\n",
    "\n",
    "# 将句子转换为列表形式，并添加结束符\n",
    "def sentence_to_list(sentence):\n",
    "    return list(sentence) + [\"<EOP>\"]\n",
    "\n",
    "\n",
    "poems = [sentence_to_list(poem) for poem in poems]\n",
    "\n",
    "\n",
    "# 创建单词到one-hot向量的映射\n",
    "def create_one_hot_vector(word, word_to_index):\n",
    "    return torch.LongTensor([word_to_index[word]])\n",
    "\n",
    "\n",
    "one_hot_vectors = {\n",
    "    word: create_one_hot_vector(word, word_to_index) for word in word_to_index\n",
    "}\n",
    "one_hot_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(sequence, one_hot_encoding):\n",
    "    # 打印原始序列（可选）\n",
    "    # print(sequence)\n",
    "\n",
    "    # 使用列表推导式生成输入和输出的 one-hot 编码\n",
    "    inputs = [one_hot_encoding[sequence[i - 1]] for i in range(1, len(sequence))]\n",
    "    outputs = [one_hot_encoding[sequence[i]] for i in range(1, len(sequence))]\n",
    "\n",
    "    # 将输入和输出列表合并为张量\n",
    "    encoded_inputs = torch.cat(inputs)\n",
    "    encoded_outputs = torch.cat(outputs)\n",
    "\n",
    "    return encoded_inputs, encoded_outputs\n",
    "\n",
    "\n",
    "# generate_sample(poems[0], one_hot_vectors)\n",
    "\n",
    "\n",
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, poems, transform=None):\n",
    "        self.poems = poems\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poems)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        poem = self.poems[index]\n",
    "        input_data, output_data = generate_sample(poem, one_hot_vectors)\n",
    "        if self.transform:\n",
    "            input_data = self.transform(input_data)\n",
    "        return input_data, output_data\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    sequences, targets = zip(*batch)\n",
    "    # 统一长度以进行批处理\n",
    "    padded_sequences = nn.utils.rnn.pad_sequence(\n",
    "        sequences, batch_first=True, padding_value=word_to_index[\"<START>\"]\n",
    "    )\n",
    "    padded_targets = nn.utils.rnn.pad_sequence(\n",
    "        targets, batch_first=True, padding_value=word_to_index[\"<START>\"]\n",
    "    )\n",
    "    return padded_sequences, padded_targets\n",
    "\n",
    "\n",
    "dataset = PoetryDataset(poems)\n",
    "data_loader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, k, heads=4, mask=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert k % heads == 0 # input vector size 必须是 heads 的整数倍\n",
    "        self.k, self.heads = k, heads\n",
    "\n",
    "        # Compute the queries, keys and values for all heads\n",
    "        self.tokeys = nn.Linear(k, k, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k, bias=False)\n",
    "        self.tovalues = nn.Linear(k, k, bias=False)\n",
    "\n",
    "        # This will be applied after the multi-head self-attention operation.\n",
    "        self.unifyheads = nn.Linear(k, k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, k = x.size()\n",
    "        h = self.heads\n",
    "\n",
    "        # 首先，为所有 heads 计算 query/key/value，得到的是完整嵌入维度的 k*k 矩阵\n",
    "        queries = self.toqueries(x)\n",
    "        keys    = self.tokeys(x)\n",
    "        values  = self.tovalues(x)\n",
    "\n",
    "        # 接下来将 queries/keys/values 切块（降维），分别送到不同的 head\n",
    "        s = k // h\n",
    "        keys    = keys.view(b, t, h, s)\n",
    "        queries = queries.view(b, t, h, s)\n",
    "        values  = values.view(b, t, h, s)\n",
    "\n",
    "        # - fold heads into the batch dimension\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "\n",
    "        # Get dot product of queries and keys, and scale\n",
    "        dot = torch.bmm(\n",
    "            queries, keys.transpose(1, 2)\n",
    "        )  # -- dot has size (b*h, t, t) containing raw weights\n",
    "        dot = dot / (k ** (1 / 2))  # scale the dot product\n",
    "        \n",
    "        # masking 操作，禁用矩阵对角线及其以下的元素，确保在预测时不会看到未来的信息\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "\n",
    "        indices = torch.triu_indices(t, t, offset=1)\n",
    "        dot[:, indices[0], indices[1]] = float('-inf')\n",
    "\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        \n",
    "        dot = F.softmax(\n",
    "            dot, dim=2\n",
    "        )  # normalize, dot now contains row-wise normalized weights\n",
    "\n",
    "        out = torch.bmm(dot, values).view(b, h, t, s) # apply the self attention to the values\n",
    "\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n",
    "\n",
    "        return self.unifyheads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, k, heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = SelfAttention(k, heads=heads)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(k)\n",
    "        self.norm2 = nn.LayerNorm(k)\n",
    "\n",
    "        self.ff = nn.Sequential(nn.Linear(k, 4 * k), nn.ReLU(), nn.Linear(4 * k, k))\n",
    "\n",
    "    def forward(self, x):\n",
    "        attended = self.attention(x)\n",
    "        x = self.norm1(attended + x)\n",
    "\n",
    "        fedforward = self.ff(x)\n",
    "        return self.norm2(fedforward + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, k, heads, depth, seq_length, num_tokens, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_emb = nn.Embedding(num_tokens, k)\n",
    "        self.pos_emb = nn.Embedding(seq_length, k)\n",
    "\n",
    "        # The sequence of transformer blocks that does all the heavy lifting\n",
    "        tblocks = []\n",
    "        for i in range(depth):\n",
    "            tblocks.append(TransformerBlock(k=k, heads=heads))\n",
    "        self.tblocks = nn.Sequential(*tblocks)\n",
    "\n",
    "        # Maps the final output sequence to class logits\n",
    "        self.toprobs = nn.Linear(k, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: A (b, t) tensor of integer values representing words (in some predetermined vocabulary).\n",
    "        :return: A (b, c) tensor of log-probabilities over the classes (where c is the nr. of classes).\n",
    "        \"\"\"\n",
    "        # generate token embeddings\n",
    "        tokens = self.token_emb(x)\n",
    "        b, t, k = tokens.size()\n",
    "\n",
    "        # generate position embeddings\n",
    "        positions = torch.arange(t)\n",
    "        positions = positions.to(device)\n",
    "        positions = self.pos_emb(positions)[None, :, :].expand(b, t, k)\n",
    "\n",
    "        x = (\n",
    "            tokens + positions\n",
    "        )  # 为什么文本嵌入和位置嵌入相加，没有理论，可能就是实验下来效果不错。\n",
    "        # https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/\n",
    "        x = self.tblocks(x)\n",
    "\n",
    "        # probabilities\n",
    "        x = self.toprobs(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    k=256, heads=4, depth=8, seq_length=512, num_tokens=vocab_size, num_classes=vocab_size\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"<START>\"], reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, num_epochs, device, optimizer, criterion):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if not batch_idx % 100:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch + 1:03d}/{num_epochs:03d} | Batch {batch_idx:05d}/{len(data_loader):05d} | Loss: {loss:.4f}\"\n",
    "                )\n",
    "        torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 00000/03915 | Loss: 9.0253\n",
      "Epoch: 001/010 | Batch 00100/03915 | Loss: 7.3220\n",
      "Epoch: 001/010 | Batch 00200/03915 | Loss: 6.9916\n",
      "Epoch: 001/010 | Batch 00300/03915 | Loss: 6.7564\n",
      "Epoch: 001/010 | Batch 00400/03915 | Loss: 6.5544\n",
      "Epoch: 001/010 | Batch 00500/03915 | Loss: 6.3860\n",
      "Epoch: 001/010 | Batch 00600/03915 | Loss: 6.1584\n",
      "Epoch: 001/010 | Batch 00700/03915 | Loss: 6.1089\n",
      "Epoch: 001/010 | Batch 00800/03915 | Loss: 6.0879\n",
      "Epoch: 001/010 | Batch 00900/03915 | Loss: 5.8858\n",
      "Epoch: 001/010 | Batch 01000/03915 | Loss: 5.5657\n",
      "Epoch: 001/010 | Batch 01100/03915 | Loss: 5.6316\n",
      "Epoch: 001/010 | Batch 01200/03915 | Loss: 5.6627\n",
      "Epoch: 001/010 | Batch 01300/03915 | Loss: 5.5743\n",
      "Epoch: 001/010 | Batch 01400/03915 | Loss: 5.7914\n",
      "Epoch: 001/010 | Batch 01500/03915 | Loss: 5.8535\n",
      "Epoch: 001/010 | Batch 01600/03915 | Loss: 5.7575\n",
      "Epoch: 001/010 | Batch 01700/03915 | Loss: 5.5250\n",
      "Epoch: 001/010 | Batch 01800/03915 | Loss: 5.7871\n",
      "Epoch: 001/010 | Batch 01900/03915 | Loss: 5.6664\n",
      "Epoch: 001/010 | Batch 02000/03915 | Loss: 5.4364\n",
      "Epoch: 001/010 | Batch 02100/03915 | Loss: 5.4706\n",
      "Epoch: 001/010 | Batch 02200/03915 | Loss: 5.4231\n",
      "Epoch: 001/010 | Batch 02300/03915 | Loss: 5.4364\n",
      "Epoch: 001/010 | Batch 02400/03915 | Loss: 5.6012\n",
      "Epoch: 001/010 | Batch 02500/03915 | Loss: 5.4570\n",
      "Epoch: 001/010 | Batch 02600/03915 | Loss: 5.4668\n",
      "Epoch: 001/010 | Batch 02700/03915 | Loss: 5.6819\n",
      "Epoch: 001/010 | Batch 02800/03915 | Loss: 5.4234\n",
      "Epoch: 001/010 | Batch 02900/03915 | Loss: 5.3506\n",
      "Epoch: 001/010 | Batch 03000/03915 | Loss: 5.2381\n",
      "Epoch: 001/010 | Batch 03100/03915 | Loss: 5.2525\n",
      "Epoch: 001/010 | Batch 03200/03915 | Loss: 5.1640\n",
      "Epoch: 001/010 | Batch 03300/03915 | Loss: 5.5317\n",
      "Epoch: 001/010 | Batch 03400/03915 | Loss: 5.0890\n",
      "Epoch: 001/010 | Batch 03500/03915 | Loss: 5.3964\n",
      "Epoch: 001/010 | Batch 03600/03915 | Loss: 5.2510\n",
      "Epoch: 001/010 | Batch 03700/03915 | Loss: 5.2150\n",
      "Epoch: 001/010 | Batch 03800/03915 | Loss: 5.2306\n",
      "Epoch: 001/010 | Batch 03900/03915 | Loss: 5.0514\n",
      "Epoch: 002/010 | Batch 00000/03915 | Loss: 5.3561\n",
      "Epoch: 002/010 | Batch 00100/03915 | Loss: 4.8358\n",
      "Epoch: 002/010 | Batch 00200/03915 | Loss: 5.0334\n",
      "Epoch: 002/010 | Batch 00300/03915 | Loss: 5.0903\n",
      "Epoch: 002/010 | Batch 00400/03915 | Loss: 5.1138\n",
      "Epoch: 002/010 | Batch 00500/03915 | Loss: 5.0296\n",
      "Epoch: 002/010 | Batch 00600/03915 | Loss: 5.2203\n",
      "Epoch: 002/010 | Batch 00700/03915 | Loss: 4.8712\n",
      "Epoch: 002/010 | Batch 00800/03915 | Loss: 5.2462\n",
      "Epoch: 002/010 | Batch 00900/03915 | Loss: 5.0691\n",
      "Epoch: 002/010 | Batch 01000/03915 | Loss: 5.0015\n",
      "Epoch: 002/010 | Batch 01100/03915 | Loss: 5.1172\n",
      "Epoch: 002/010 | Batch 01200/03915 | Loss: 4.8402\n",
      "Epoch: 002/010 | Batch 01300/03915 | Loss: 4.9176\n",
      "Epoch: 002/010 | Batch 01400/03915 | Loss: 5.1057\n",
      "Epoch: 002/010 | Batch 01500/03915 | Loss: 4.9600\n",
      "Epoch: 002/010 | Batch 01600/03915 | Loss: 4.8175\n",
      "Epoch: 002/010 | Batch 01700/03915 | Loss: 5.0597\n",
      "Epoch: 002/010 | Batch 01800/03915 | Loss: 4.8571\n",
      "Epoch: 002/010 | Batch 01900/03915 | Loss: 4.8485\n",
      "Epoch: 002/010 | Batch 02000/03915 | Loss: 4.5603\n",
      "Epoch: 002/010 | Batch 02100/03915 | Loss: 4.8090\n",
      "Epoch: 002/010 | Batch 02200/03915 | Loss: 4.9502\n",
      "Epoch: 002/010 | Batch 02300/03915 | Loss: 5.0420\n",
      "Epoch: 002/010 | Batch 02400/03915 | Loss: 4.9963\n",
      "Epoch: 002/010 | Batch 02500/03915 | Loss: 4.8125\n",
      "Epoch: 002/010 | Batch 02600/03915 | Loss: 4.8035\n",
      "Epoch: 002/010 | Batch 02700/03915 | Loss: 4.6542\n",
      "Epoch: 002/010 | Batch 02800/03915 | Loss: 4.8864\n",
      "Epoch: 002/010 | Batch 02900/03915 | Loss: 4.7511\n",
      "Epoch: 002/010 | Batch 03000/03915 | Loss: 4.8008\n",
      "Epoch: 002/010 | Batch 03100/03915 | Loss: 4.4663\n",
      "Epoch: 002/010 | Batch 03200/03915 | Loss: 4.7744\n",
      "Epoch: 002/010 | Batch 03300/03915 | Loss: 4.6778\n",
      "Epoch: 002/010 | Batch 03400/03915 | Loss: 4.5605\n",
      "Epoch: 002/010 | Batch 03500/03915 | Loss: 4.7270\n",
      "Epoch: 002/010 | Batch 03600/03915 | Loss: 4.8643\n",
      "Epoch: 002/010 | Batch 03700/03915 | Loss: 4.8994\n",
      "Epoch: 002/010 | Batch 03800/03915 | Loss: 4.6757\n",
      "Epoch: 002/010 | Batch 03900/03915 | Loss: 4.4727\n",
      "Epoch: 003/010 | Batch 00000/03915 | Loss: 4.5173\n",
      "Epoch: 003/010 | Batch 00100/03915 | Loss: 4.2535\n",
      "Epoch: 003/010 | Batch 00200/03915 | Loss: 4.6778\n"
     ]
    }
   ],
   "source": [
    "train(model, data_loader, num_epochs, device, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['原']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     43\u001b[0m             input_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([input_vector, torch\u001b[38;5;241m.\u001b[39mLongTensor([selected_index])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m原\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m月\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m泉\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(start_word, top_k, log)\u001b[0m\n\u001b[1;32m      5\u001b[0m     words \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [word]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(words)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      8\u001b[0m     vectors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_text(start_word=\"<START>\", top_k=1, log=False):\n",
    "    generated_text = \"\"\n",
    "    words = []\n",
    "    for word in start_word:\n",
    "        words += [word]\n",
    "    print(words)\n",
    "    with torch.no_grad():\n",
    "        vectors_list = []\n",
    "        for word in words:\n",
    "            word_vector = torch.LongTensor([word_to_index[word]]).unsqueeze(0)\n",
    "            vectors_list.append(word_vector)\n",
    "            generated_text += word\n",
    "\n",
    "        input_vector = torch.cat(vectors_list, dim=1)\n",
    "        \n",
    "        for _ in range(context_len - len(words)):\n",
    "            \n",
    "            output = model(input_vector.to(device))\n",
    "            \n",
    "            last_word = output[:, -1, :]\n",
    "            last_word = last_word.view(-1)\n",
    "            top_values, top_indices = last_word.data.topk(top_k)\n",
    "\n",
    "            probabilities = torch.exp(top_values)\n",
    "            top_words = [index_to_word[index.item()] for index in top_indices]\n",
    "\n",
    "            probabilities_np = probabilities.cpu().detach().numpy()\n",
    "            probabilities_np = probabilities_np / probabilities_np.sum()\n",
    "            indices_np = top_indices.cpu().detach().numpy()\n",
    "            if log:\n",
    "                for word, prob in zip(top_words, probabilities_np):\n",
    "                    print(f\"{word}: {prob:.4f}\")\n",
    "\n",
    "            selected_index = np.random.choice(indices_np, p=probabilities_np)\n",
    "\n",
    "            next_word = index_to_word[selected_index]\n",
    "            if next_word == \"<EOP>\":\n",
    "                break\n",
    "            generated_text += next_word\n",
    "            if log:\n",
    "                print(generated_text)\n",
    "            # * 需要升一个维, 因为模型的输入以 batch 为单位\n",
    "            input_vector = torch.cat([input_vector, torch.LongTensor([selected_index]).unsqueeze(0)], dim=1)\n",
    "\n",
    "    return generated_text.strip()\n",
    "\n",
    "\n",
    "print(generate_text(\"原\", top_k=1))\n",
    "print(generate_text(\"月\", top_k=3))\n",
    "print(generate_text(\"泉\", top_k=3))\n",
    "print(generate_text(\"日\", top_k=30))\n",
    "print(generate_text(\"沾衣欲湿杏花雨\", top_k=3))\n",
    "print(generate_text(\"风\", top_k=3, log=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
